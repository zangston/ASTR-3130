{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of Images\n",
    "After we get a bunch of images, we first need to preprocess them. This step mainly includes\n",
    "* Overscan calibration (apply to all images)\n",
    "\n",
    "Overscan region records the changes of ground voltage during readout. Since what is really measured is the voltage difference between ground and each pixel, one need to make sure that ground is the same during one readout. This region usually appears to be purely black since the change is usually small even when compared to sky brightness. However, many detectors do not have overscan region, so this step is often skipped.\n",
    "* Bias calibration (apply to dark, flat and light)\n",
    "\n",
    "Detectors are usually precharged to a certain votage (offset) to avoid clipping when the signal is low. This offset needs to be removed. By reading out once immediately after another, one could get an image with this offset plus the readout noise.\n",
    "* Dark calibration (apply to flat and light)\n",
    "\n",
    "Even when there is no photoelectron, due to non-zero temperature (in Kelvin), electrons are still being excited onto higher energy levels and creating \"signals\". This term is called dark current because it scales linearly with exposure time. It needs to be subtracted from the image. By taking an image with shutter closed, one could get an image composed of dark current, readout noise and the offset.\n",
    "* Flat calibration (apply to light)\n",
    "\n",
    "Some pixels are more sensitive to light but others are less. The optics can also have vignetting and dust particles blocking light. By taking an image of an uniformly illuminated object, one could measure the response of the optical system + detector and correct it out.\n",
    "\n",
    "Normally, we take multiple dark, flat and bias fields. Before we start we need to combine them into one master frame. The process is the same as stacking aligned images. In short\n",
    "$$\\rm Master\\ Bias=<Bias_i>$$\n",
    "$$\\rm Master\\ Dark=<Dark_i-Master\\ Bias>$$\n",
    "$$\\rm Master\\ Flat=<Flat_i-Master\\ Bias-a\\times Master\\ Dark>$$\n",
    "\n",
    "After that, we can calibrate the light images\n",
    "\n",
    "$$\\rm Calibrated\\ Light=\\frac{Light-Master\\ Bias-b\\times Master\\ Dark}{Master\\ Flat}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules and functions\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.constants as c\n",
    "from astropy.io import fits\n",
    "from astropy import log\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import astropy.units as u\n",
    "import ccdproc\n",
    "from ccdproc import ccd_process, combine\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "log.setLevel('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating master bias, dark and flat images\n",
    "Master calibration images are created by stacking (averaging) over many individual calibration images. Individual calibration images can have small differences in its mean value, especially for individual sky flats. Therefore, we need to linearly scale the images before averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_clipped_mean(img_data, xlim, ylim):\n",
    "    '''\n",
    "    Scaling images according to its 10 times 3-sigma clipped mean.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_data: array-like, the input image data\n",
    "    xlim: 2-list, the maximum and minimum of x corrdinate of the region\n",
    "    ylim: 2-list, the maximum and minimum of y corrdinate of the region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    m: float, the scaling factor of the image\n",
    "    '''\n",
    "    m = 1.0 / sigma_clipped_stats(img_data[xlim[0]: xlim[1], ylim[0]: ylim[1]], maxiters=10)[0]\n",
    "    return m\n",
    "\n",
    "\n",
    "def median_scaling(img_data, xlim, ylim):\n",
    "    '''\n",
    "    Scaling images according to its median within a region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_data: array-like, the input image data\n",
    "    xlim: 2-list, the maximum and minimum of x corrdinate of the region\n",
    "    ylim: 2-list, the maximum and minimum of y corrdinate of the region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scaling: float, the scaling factor of the image\n",
    "    '''\n",
    "    scaling = 1.0 / np.nanmedian(img_data[xlim[0]: xlim[1], ylim[0]: ylim[1]])\n",
    "    return scaling\n",
    "\n",
    "\n",
    "def stack(areg, oname, unit='adu', method = 'median', scaling=None, extremeclip=[1, 1], sigmaclip=[4.0, 3.0]):\n",
    "    '''\n",
    "    Stack images with extreme value clipping and sigma clipping\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    areg: str, filename pattern of images\n",
    "    outdir: str, output directory for processed data, this directory must exist beforehand\n",
    "    unit: optional, str or astropy.units, default astropy.units.adu, the unit that the pixel data of the light images are in\n",
    "    method: optional, str, default median, method to combine images based on what images you are using, options are average, median, sum\n",
    "    scaling: optional, function, default sigma_clipped_mean, the scaling function for each frame\n",
    "    extremeclip: optional, list with length=2, default [1, 1], the lowest extremeclip[0] and highest extremeclip[1] values will be clipped\n",
    "    sigmaclip: optional, list with length=2, default [4.0, 3.0], the low threshold and high threshold in sigma\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    alist = glob.glob(areg)\n",
    "    # Stacking\n",
    "    # Caveat: everything is saved in memory, so be careful when processing more than 4GB of images\n",
    "    # Caveat: header is broken in many ways. EXPTIME, GAIN, RDNOISE, MJD_OBS are not updated\n",
    "    outdata = combine(alist, method= method, scale=scaling, unit=unit,\n",
    "                      clip_extrema=True, nlow=extremeclip[0], nhigh=extremeclip[1],\n",
    "                      sigma_clip=True, sigma_clip_low_thresh=sigmaclip[0], sigma_clip_high_thresh=sigmaclip[1])\n",
    "    outdata.write(oname, overwrite=True)\n",
    "    print(\"Stack Finished\")\n",
    "    \n",
    "\n",
    "def calibrate(lreg, mbias, mdark, mflat, outdir, unit='adu', exptime='EXPTIME', darkscale=True):\n",
    "    '''\n",
    "    Bias, dark and flat calibrate images\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lreg: str, filename pattern of images\n",
    "    mbias: astropy.nddata.CCDData, CCDData containing master bias\n",
    "    mdark: astropy.nddata.CCDData, CCDData containing master dark\n",
    "    mflat: astropy.nddata.CCDData, CCDData containing master flat\n",
    "    outdir: str, output directory for processed data, this directory must exist beforehand\n",
    "    unit: optional, str or astropy.units, default 'adu', the unit that the pixel data of the light images are in\n",
    "    exptime: optional, str, default 'EXPTIME', the key for exposure time of the light images\n",
    "    darkscale: optional, boolean, default True, whether to scale master dark according to exposure time\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    for each_l in glob.glob(lreg):\n",
    "        lccd = CCDData.read(each_l, unit=unit)\n",
    "        # Yeah, this package is inspired by iraf\n",
    "        rccd = ccd_process(lccd, master_bias=mbias, dark_frame=mdark, master_flat=mflat, \n",
    "                           exposure_key=exptime, dark_scale=darkscale, exposure_unit=u.s,\n",
    "                           gain_corrected=False)\n",
    "        rccd.write(os.path.join(outdir, os.path.basename(each_l)), overwrite=True)\n",
    "     \n",
    "    print(\"Calibration Finished\")\n",
    "\n",
    "def imexamine(ireg, xlim, ylim, unit='adu'):\n",
    "    '''\n",
    "    Examine an image and print out the mean, median, std, min and max within a region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ireg: str, filename pattern of images\n",
    "    xlim: 2-list, the maximum and minimum of x corrdinate of the region\n",
    "    ylim: 2-list, the maximum and minimum of y corrdinate of the region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    print('File  Mean  Median  Std  Min  Max')\n",
    "    for each in glob.glob(ireg):\n",
    "        iccd = CCDData.read(each, unit=unit)\n",
    "        img_mean, img_med, img_std = sigma_clipped_stats(iccd.data[xlim[0]: xlim[-1], ylim[0]: ylim[-1]])\n",
    "        img_min, img_max = np.nanmin(iccd.data), np.nanmax(iccd.data[xlim[0]: xlim[-1], ylim[0]: ylim[-1]])\n",
    "        print(str(each) + ' %.4f %.4f %.4f %.4f %.4f' % (img_mean, img_med, img_std, img_min, img_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating master bias is an easy process. We just stack them. However, we would like to check that there are no outliers in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master bias\n",
    "imexamine('*Bias*',[1024, 3072], [1024, 3072])\n",
    "stack('*Bias*', \"mbias.fits\", scaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating master dark is not a hard process. We first calibrate individual dark images with master bias, and then we stack them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imexamine('mbias.fits',[1024, 3072], [1024, 3072])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master dark\n",
    "imexamine('*Dark*', [1024, 3072], [1024, 3072])\n",
    "# imexamine('Test_300s_Dark*', [1024, 3072], [1024, 3072])\n",
    "os.makedirs('calibrated', exist_ok=True)\n",
    "mbias = CCDData.read('mbias.fits', unit='adu')\n",
    "calibrate('Test_Dark*', mbias, None, None, 'calibrated') # Calibrate 60 sec darks\n",
    "calibrate('Test_300s_Dark*', mbias, None, None, 'calibrated') # Calibrate 300 sec darks\n",
    "stack('./calibrated/Test_Dark*', \"./mdark_60s.fits\",scaling=None)  # Stacking 60 sec dark\n",
    "stack('./calibrated/Test_300s_Dark*', \"./mdark_300s.fits\",scaling=None)  # Stacking 300 sec dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imexamine('mdark*',[1024, 3072], [1024, 3072])\n",
    "imexamine('mbias.fits', [1024, 3072], [1024, 3072])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating master flat is the most difficult of all three. We first calibrate individual flat images with master bias and master flat, and then we stack them. However, different flat can have very different overall brightness, so we need to scale them before stacking. We cannot scale the entire image with its global median since there are vignetting, so we evaluate the median with only the center quarter of the image and then scale them. However, we have provided master flat, so this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master flat\n",
    "# Flat field has vignetting, so instead of scaling the image with its global median, we scale it with the median in the central region\n",
    "imexamine('RRRT_mflat_V_616988.fits', [1024, 3072], [1024, 3072])\n",
    "# median_half = lambda x: median_scaling(x, [1024, 3072], [1024, 3072])\n",
    "# mdark_60 = CCDData.read('mdark_60s.fits', unit='adu')\n",
    "# mdark_300 = CCDData.read('mdark_300s.fits', unit='adu')\n",
    "# calibrate('./Flat/FLAT_*.fits', mbias, mdark_300, None, './calibrated')\n",
    "# stack('./calibrated/FLAT_*.fits', \"./mflat_V.fits\", scaling=median_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating light images\n",
    "Now we can calibrate all light images. Nice and easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light images\n",
    "mflat_v = CCDData.read('RRRT_mflat_V_616988.fits', unit='adu')\n",
    "mdark_60 = CCDData.read('mdark_60s.fits', unit='adu')\n",
    "mdark_300s = CCDData.read('mdark_300s.fits', unit='adu')\n",
    "calibrate('Test_M37.fit', mbias, mdark_60, mflat_v, './calibrated')  # Calibrate M37 image\n",
    "calibrate('Test_M81.fit', mbias, mdark_300s, mflat_v, './calibrated')  # Calibrate M81 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching the images\n",
    "For the galaxy image, we want to stretch the image and look at the details of the galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scurveRNC01(img_data):\n",
    "    '''\n",
    "    scurve1 (contrast enhancement transformation) in RNC-color correction. Adapted from c source file.\n",
    "\n",
    "    More details, please visit:\n",
    "        http://www.clarkvision.com/articles/astrophotography-rnc-color-stretch/\n",
    "        \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_data: 2D numpy.array, the input image data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tmp: 2D numpy.array, the output image data\n",
    "    '''\n",
    "    zp = 5.0 / (1.0 + np.exp(2.1)) - 0.58\n",
    "    op = 5.0 / (1.0 + np.exp(-2.9)) - 0.58 - zp\n",
    "    tmp = 5.0 / (1.0 + np.exp(-5.0 * (img_data - 0.42))) - 0.58\n",
    "    tmp = (tmp - zp) / op\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def midtone_transformation(img_data, low_clip=2.8, bg=0.25):\n",
    "    '''\n",
    "    Transformation used in many commercial image processing softwares\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_data: 2D numpy.array, the input image data\n",
    "    low_clip: float, the shadow clipping point in sigma\n",
    "    bg: float, the desired background value after transformation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img_stretched: 2D numpy.array, the stretched image data\n",
    "    '''\n",
    "    img_mean, _, img_std = sigma_clipped_stats(img_data, maxiters=10)\n",
    "    # Clipping\n",
    "    img_clipped = np.copy(img_data) - (img_mean - low_clip * img_std)\n",
    "    img_clipped[img_clipped < 0.0] = 0.0\n",
    "    # Solve for midtone\n",
    "    img_mean = low_clip * img_std\n",
    "    m = img_mean * (1.0 - bg) / (img_mean - 2.0 * bg * img_mean + bg)\n",
    "    img_stretched = (m - 1.0) * img_clipped / ((2.0 * m - 1.0) * img_clipped - m)\n",
    "    return img_stretched\n",
    "\n",
    "\n",
    "img_m81 = CCDData.read(\"./calibrated/Test_M81.fit\").data / 65535.0  # The stretch function would only work when pixel values are between 0 and 1\n",
    "img_stretched = midtone_transformation(img_m81, bg=0.2)\n",
    "# Contrast enhancement\n",
    "for i in range(2):\n",
    "    img_stretched = scurveRNC01(img_stretched)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img_stretched, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# plt.savefig(\"M81_stretched.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, hdr= fits.getdata(\"./calibrated/Test_M81.fit\",header=True)\n",
    "# fits.writeto(\"M81_300s_stretched.fits\",img_stretched,header=hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
